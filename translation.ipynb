{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47205e5e-d28c-43aa-8525-b608721c3ba6",
   "metadata": {},
   "source": [
    "#### Import required modules and load alpaca_data_cleaned file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b1c1e6e-5984-4dbf-a124-45eb78a1da1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T21:35:00.955760Z",
     "start_time": "2023-07-24T21:34:59.307887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepl in /opt/homebrew/lib/python3.11/site-packages (1.15.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/lib/python3.11/site-packages (from deepl) (2.28.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2->deepl) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2->deepl) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2->deepl) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2->deepl) (2022.12.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: openai in /opt/homebrew/lib/python3.11/site-packages (0.27.0)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/homebrew/lib/python3.11/site-packages (from openai) (2.28.2)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/lib/python3.11/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.20->openai) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->openai) (22.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->openai) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->openai) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install deepl\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ba1146-8564-40db-a1a7-2883458da43c",
   "metadata": {},
   "source": [
    "#### Choose the translator you would like to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a355bf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T21:35:15.404573Z",
     "start_time": "2023-07-24T21:35:14.352321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deepl\n",
      "  Using cached deepl-1.15.0-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from deepl) (2.28.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2->deepl) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2->deepl) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2->deepl) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2->deepl) (1.26.14)\n",
      "Installing collected packages: deepl\n",
      "Successfully installed deepl-1.15.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.10 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install deepl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d59f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c778000d-7512-45b8-807e-a694400932a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T21:35:16.833049Z",
     "start_time": "2023-07-24T21:35:16.822326Z"
    }
   },
   "outputs": [],
   "source": [
    "TRANSLATOR = \"deepl\" # or openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c936db98-c9ac-4846-80e7-3273d54e2ecb",
   "metadata": {},
   "source": [
    "#### Authenticate to deepl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfadb081-c3ce-4ebf-ba09-5c0894360212",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T21:39:54.258651Z",
     "start_time": "2023-07-24T21:39:54.248419Z"
    }
   },
   "outputs": [],
   "source": [
    "import deepl\n",
    "\n",
    "TARGET_LANG=\"ES\" # e.g. DE, EN,.. \n",
    "FORMALITY=\"less\" # \n",
    "\n",
    "auth_key = \"0945e2ef-b902-3627-61ca-43785203ae37:fx\"  # replace with your key\n",
    "translator = deepl.Translator(auth_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfdfc8f-6116-4a55-b1ba-4955b6ad4b83",
   "metadata": {},
   "source": [
    "#### Setup OpenAI information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a586b34-09ac-467e-887e-ea24b28f55eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T21:39:07.829381Z",
     "start_time": "2023-07-24T21:39:07.825896Z"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"\" # replace with your key\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "TARGET_LANGUAGE = \"Spanish\" # e.g. \"English\", \"German\", \"Spanish\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cf8411b-bf64-4872-9f24-f17f686456a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T21:41:11.148142Z",
     "start_time": "2023-07-24T21:41:11.119848Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "\n",
    "input_tasks_path = \"data/source_tasks/tasks_translated_en.json\"\n",
    "\n",
    "with open(input_tasks_path, \"rb\") as f:\n",
    "    json_data = json.loads(f.read())\n",
    "    df = pd.DataFrame(json_data)\n",
    "    \n",
    "def write_json_file(blob, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "            json.dump(blob, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0527cad4-47ca-49b0-be9e-58e54899ce46",
   "metadata": {},
   "source": [
    "### Start translating dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4407cfe-557a-46e8-8bed-1a467d618a61",
   "metadata": {},
   "source": [
    "#### util functions that help avoid translating content that is not intended for translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cc27072-806d-4b0f-8730-d06b4a95f834",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T21:40:43.550802Z",
     "start_time": "2023-07-24T21:40:43.543959Z"
    }
   },
   "outputs": [],
   "source": [
    "def matches_regex(regex, text):\n",
    "    return bool(re.compile(regex).search(text))\n",
    "\n",
    "\n",
    "def contains_code(text):\n",
    "    # filter based on keywords that indicate code\n",
    "    code_blacklist = ['&&', '||', '<html>', ';\\n', 'SELECT']\n",
    "    \n",
    "    return (\n",
    "            any(code_keyword in text for code_keyword in code_blacklist) |\n",
    "            matches_regex(r'\\w+\\(\\w*\\) \\{', text) | # e.g. myFunc() {\n",
    "            matches_regex(r'def \\w+\\(', text) | # e.g. def parse_list(\n",
    "            matches_regex(r'\\[A-z]+\\.[A-z]+', text) | # e.g. this.language\n",
    "            matches_regex(r': [\\w\\.#]{1,12};', text) | # e.g. font-size: 1.3em;\n",
    "            matches_regex(r'<\\/\\w+>', text) # e.g. </html>\n",
    "           )\n",
    "\n",
    "\n",
    "def contains_words(text):\n",
    "    return matches_regex(r'[A-z]{3,}', text) # words with at least three characters\n",
    "\n",
    "\n",
    "def is_translatable(text):\n",
    "    if text == \"\":\n",
    "        return True # empty string won't be charged by DeepL\n",
    "    return (contains_code(text) is False) & contains_words(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c813ed6-f555-4733-9e41-8300aaf29f12",
   "metadata": {},
   "source": [
    "#### util functions to translate individual columns (instruction, input and output) of each chunck as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c68b81f0-217a-43e0-b607-2c04489690b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T21:40:45.487322Z",
     "start_time": "2023-07-24T21:40:45.471056Z"
    }
   },
   "outputs": [],
   "source": [
    "def translate_and_update_series(text_series):\n",
    "    # memorize whether and where the list contains non-translatable content\n",
    "    is_translatable_index = text_series.apply(lambda x: is_translatable(x) is False)\n",
    "    text_list_source_language = text_series.tolist()\n",
    "\n",
    "    # replace non-translatable content with an empty string\n",
    "    text_series[is_translatable_index] = \"\"\n",
    "\n",
    "    # translate list\n",
    "    text_list = text_series.tolist()\n",
    "    if TRANSLATOR == \"deepl\":\n",
    "        translated_list = translate_list_deepl(text_list)\n",
    "    else:\n",
    "        translated_list = translate_list_openai(text_list)\n",
    "\n",
    "    # if list contains non-translatable content, replace accordingly\n",
    "    if is_translatable_index.sum() > 0:\n",
    "        for index, text_is_translatable in enumerate(is_translatable_index.tolist()):\n",
    "            if text_is_translatable:\n",
    "                translated_list[index] = text_list_source_language[index]\n",
    "    return translated_list\n",
    "\n",
    "def create_openai_prompt_string(text):\n",
    "    if ' ' in text:\n",
    "        return f'Please provide the {TARGET_LANGUAGE} translation for these sentences: {text}'\n",
    "    else:\n",
    "        return f'Please provide the {TARGET_LANGUAGE} translation for the following word: {text}'\n",
    "\n",
    "def create_openai_message_list(text_list):\n",
    "    return [None if text == \"\" else {\"role\": \"user\", \"content\": create_openai_prompt_string(text)} for text in text_list]\n",
    "\n",
    "def translate_openai_message(message):\n",
    "    if message is None:\n",
    "        return \"\"\n",
    "    \n",
    "    response = None\n",
    "    while response is None:\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=MODEL,\n",
    "                messages=[message]\n",
    "            )\n",
    "        except:\n",
    "            pass\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "def translate_list_openai(text_list):\n",
    "    message_list = create_openai_message_list(text_list)\n",
    "    return [translate_openai_message(message) for message in message_list]\n",
    "\n",
    "def translate_list_deepl(text_list):\n",
    "    # here would be the place to replace the DeepL library with the Google library for example\n",
    "    combined_response = translator.translate_text(text_list, source_lang=\"EN\", target_lang=TARGET_LANG, formality=FORMALITY)\n",
    "    return [response.text for response in combined_response]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd08a21-53cd-4847-9f57-c2c86f5176ee",
   "metadata": {},
   "source": [
    "#### Divide dataframe into chunks and translate the chunks sequentially\n",
    "\n",
    "I'm sure this part can be heavily improved (feel free to create a pull request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fe2e739-6efe-4d29-ab73-546df48260ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T21:40:55.507881Z",
     "start_time": "2023-07-24T21:40:55.500961Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feel free to increase the chunk size. I was worried that the execution would be interrupted,\n",
    "# so I used a smaller chunk size\n",
    "chunk_size = 5\n",
    "output_dir = './data/output/'\n",
    "\n",
    "def translate_dataframe(df):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    number_of_chunks = df.shape[0] // chunk_size\n",
    "    chunked_df_list = np.array_split(df, number_of_chunks)\n",
    "    \n",
    "    start_index = 1\n",
    "    \n",
    "    for index, chunk_df in enumerate(chunked_df_list[start_index:]):\n",
    "        instruction_list_translated = translate_and_update_series(chunk_df.instruction)\n",
    "        input_list_translated = translate_and_update_series(chunk_df.input)\n",
    "        output_list_translated = translate_and_update_series(chunk_df.output)\n",
    "        \n",
    "        translated_df = pd.DataFrame({'instruction': instruction_list_translated, 'input': input_list_translated, 'output': output_list_translated})\n",
    "        translated_dict = translated_df.to_dict('records')\n",
    "        \n",
    "        write_json_file(translated_dict, f'{output_dir}chunk{start_index+index}.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fec387c-4c39-41cd-a168-c63333830a1e",
   "metadata": {},
   "source": [
    "#### Start translating the DataFrame (Warning: Run this cell carefully)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa1f9a01-41b7-4551-8211-9cc90a84dabd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T21:59:24.322462Z",
     "start_time": "2023-07-24T21:42:06.073274Z"
    }
   },
   "outputs": [
    {
     "ename": "QuotaExceededException",
     "evalue": "Quota for this billing period has been exceeded, message: Quota Exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mQuotaExceededException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtranslate_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [15], line 16\u001b[0m, in \u001b[0;36mtranslate_dataframe\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     14\u001b[0m instruction_list_translated \u001b[38;5;241m=\u001b[39m translate_and_update_series(chunk_df\u001b[38;5;241m.\u001b[39minstruction)\n\u001b[1;32m     15\u001b[0m input_list_translated \u001b[38;5;241m=\u001b[39m translate_and_update_series(chunk_df\u001b[38;5;241m.\u001b[39minput)\n\u001b[0;32m---> 16\u001b[0m output_list_translated \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate_and_update_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m translated_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstruction\u001b[39m\u001b[38;5;124m'\u001b[39m: instruction_list_translated, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m: input_list_translated, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m: output_list_translated})\n\u001b[1;32m     19\u001b[0m translated_dict \u001b[38;5;241m=\u001b[39m translated_df\u001b[38;5;241m.\u001b[39mto_dict(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn [14], line 12\u001b[0m, in \u001b[0;36mtranslate_and_update_series\u001b[0;34m(text_series)\u001b[0m\n\u001b[1;32m     10\u001b[0m text_list \u001b[38;5;241m=\u001b[39m text_series\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TRANSLATOR \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepl\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 12\u001b[0m     translated_list \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate_list_deepl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     translated_list \u001b[38;5;241m=\u001b[39m translate_list_openai(text_list)\n",
      "Cell \u001b[0;32mIn [14], line 53\u001b[0m, in \u001b[0;36mtranslate_list_deepl\u001b[0;34m(text_list)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranslate_list_deepl\u001b[39m(text_list):\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# here would be the place to replace the DeepL library with the Google library for example\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     combined_response \u001b[38;5;241m=\u001b[39m \u001b[43mtranslator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_lang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_lang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTARGET_LANG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFORMALITY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m combined_response]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/deepl/translator.py:827\u001b[0m, in \u001b[0;36mTranslator.translate_text\u001b[0;34m(self, text, source_lang, target_lang, split_sentences, preserve_formatting, formality, glossary, tag_handling, outline_detection, non_splitting_tags, splitting_tags, ignore_tags)\u001b[0m\n\u001b[1;32m    821\u001b[0m     request_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m join_tags(ignore_tags)\n\u001b[1;32m    823\u001b[0m status, content, json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_call(\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv2/translate\u001b[39m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m=\u001b[39mrequest_data\n\u001b[1;32m    825\u001b[0m )\n\u001b[0;32m--> 827\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m translations \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranslations\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n\u001b[1;32m    830\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/deepl/translator.py:578\u001b[0m, in \u001b[0;36mTranslator._raise_for_status\u001b[0;34m(self, status_code, content, json, glossary, downloading_document)\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AuthorizationException(\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthorization failure, check auth_key\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    575\u001b[0m         http_status_code\u001b[38;5;241m=\u001b[39mstatus_code,\n\u001b[1;32m    576\u001b[0m     )\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m status_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_HTTP_STATUS_QUOTA_EXCEEDED:\n\u001b[0;32m--> 578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m QuotaExceededException(\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuota for this billing period has been exceeded\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    580\u001b[0m         http_status_code\u001b[38;5;241m=\u001b[39mstatus_code,\n\u001b[1;32m    581\u001b[0m     )\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m status_code \u001b[38;5;241m==\u001b[39m http\u001b[38;5;241m.\u001b[39mHTTPStatus\u001b[38;5;241m.\u001b[39mNOT_FOUND:\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m glossary:\n",
      "\u001b[0;31mQuotaExceededException\u001b[0m: Quota for this billing period has been exceeded, message: Quota Exceeded"
     ]
    }
   ],
   "source": [
    "translate_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e23d3a5-ed8a-462f-8b3d-76c4f17614bc",
   "metadata": {},
   "source": [
    "#### Finally combine all chunked files into one translated task file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b5f434e-dacc-4432-97b5-afe6fe7a7b06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T22:27:59.313322Z",
     "start_time": "2023-07-24T22:27:59.219651Z"
    }
   },
   "outputs": [],
   "source": [
    "def combine_chunks():\n",
    "    translated_tasks_list = []\n",
    "    for index in range(1, len(glob.glob(f'{output_dir}*.json'))):\n",
    "        with open(f'{output_dir}chunk{index}.json', \"rb\") as f:\n",
    "            translated_tasks_list += json.loads(f.read())\n",
    "    write_json_file(translated_tasks_list, f'./translated_tasks_es_{TRANSLATOR}.json')\n",
    "\n",
    "combine_chunks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cbc50c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
